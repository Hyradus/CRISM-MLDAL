{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spectral import envi\n",
    "import numpy as np\n",
    "from tkinter import Tk,filedialog\n",
    "from argparse import ArgumentParser\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import ntpath\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to obtain the namefile for the csv and hdf\n",
    "def path_leaf(tgtname):\n",
    "    head, tail = ntpath.split(tgtname)\n",
    "    return tail or ntpath.basename(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperspectral cube is read from the hdr file relative to a CRISM image. In this case from a calibreted I/F MTRDR.\n",
    "To read the hdr file, i used the module envi from the spectral library.\n",
    "The hyperspectral cube is opened as a masked numpy 3-D array [width, height, wavelength]. then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2np(hdrfile):\n",
    "    imgfile = envi.open(hdrfile)\n",
    "    #read hdr files\n",
    "    header_hdr = envi.read_envi_header(hdrfile)\n",
    "    #create cube\n",
    "    cube = imgfile[:,:,:]\n",
    "    #replace \"nodata\" values with np.nan\n",
    "    #cube_np_nan = np.where(cube < cube.max(), cube, np.nan)\n",
    "    #create index for wavelengths\n",
    "    cube_masked = np.ma.masked_where(cube == cube.max(), cube, copy=True)\n",
    "    names = header_hdr['wavelength']\n",
    "    return(cube_masked, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function initialize and empty pandas dataframe, then read every slice (image) of the hyperspectral cube, flatten the image, convert to a pandas's series and append to the initial dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CUBE_np2df(np_cube, names):\n",
    "    cube_df = pd.DataFrame()\n",
    "    for i in range(len(names)):\n",
    "        img_slice = np_cube[:,:,i]\n",
    "        series = pd.Series(data=img_slice.flatten(), name=names[i])\n",
    "        cube_df[series.name] = series        \n",
    "    return(cube_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following functions are dedicated to save the dataframe in csv and hdf format and print the timings. Both files are saved in the same folder of the hdr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CUBE_df2csv(cube_df, hdrfile):\n",
    "    dfname = path_leaf(hdrfile)\n",
    "    savepath = os.path.dirname(hdrfile)\n",
    "    savename = savepath + '/' + dfname + '.csv'\n",
    "    start = timer()\n",
    "    %time cube_df.to_csv(savename, index=False)\n",
    "    end = timer()\n",
    "    print(savename, ' csv exported in: ', savepath, 'in: ', end-start, 's')\n",
    "    return(end-start)\n",
    "\n",
    "def CUBE_df2hdf(cube_df, hdrfile):\n",
    "    dfname = path_leaf(hdrfile)\n",
    "    savepath = os.path.dirname(hdrfile)\n",
    "    savename = savepath + '/' + dfname + '.hdf'\n",
    "    start = timer()\n",
    "    %time cube_df.to_hdf(savename, 'df')\n",
    "    end = timer()\n",
    "    print(savename, ' hdf exported in: ', savepath, 'in: ', end-start, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function simply call all the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(hdrfile):\n",
    "    cube_np_nan, names = img2np(hdrfile)\n",
    "    cube_df = CUBE_np2df(cube_np_nan, names)\n",
    "    \n",
    "    print('Saving to csv')\n",
    "    #export cube to csv\n",
    "    #csv_time = CUBE_df2csv(cube_df, hdrfile) UNCOMMENT TO SAVE CSV\n",
    "    print('Saving to hdf')\n",
    "    #export cube to hdf\n",
    "    hdf_time = CUBE_df2hdf(cube_df, hdrfile)\n",
    "    #return(cube_np_nan, cube_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main code initialize a parser to accept the path to the hdr files, and if not given, ask interactively to browse to the file. Then run the main function. Note that this cannot be executed yet on jupiter because of the argparser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--hdrf', help='Select*.hdr file.')\n",
    "    args = parser.parse_args()\n",
    "    hdrfile = args.hdrf\n",
    "    \n",
    "    if args.hdrf is None:\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        hdrfile = filedialog.askopenfilename(parent=root,initialdir=os.getcwd(),title=\"Please select hdr file:\",\n",
    "                                             filetypes= (('hdr files', '*.hdr'), ('all files', '*.*)))')))\n",
    "        print('hdr file selected: ', hdrfile)        \n",
    "    else:\n",
    "        modpath = args.wdir\n",
    "\n",
    "main(hdrfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
